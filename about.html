<div class="subreddit-header">
    <div class="community-banner" style="background-image: url(./src/img/banner.webp);"></div>
    </div>
    <section class="community-actions">
        <div class="content-wrapper">
            <div class="icon-wrapper">
            <div class="icon">
                <faceplate-img src="https://styles.redditmedia.com/t5_6/styles/communityIcon_a8uzjit9bwr21.png" class="community-icon"></faceplate-img>
            </div>
            <div class="title-wrapper">
                <h1>Reddit Sentiment Analysis</h1>
            </div>
            </div>
        </div>
    </section>
</div>
<div class="subreddit-content">
    <div class="middle-content">
        <hr class="w-100 my-sm border-neutral-border-weak">
        <div class="chapter">
            <div class="chapter-title">Purpose</div>
            <div class="chapter-content">
                <p>The purpose of this project is to analyze user comments on various subreddits on <a href="https://www.reddit.com/">Reddit</a> to determine the predominant emotional tendencies of the comments in each subreddit.</p>
            </div>
        </div>
        <hr class="w-100 my-sm border-neutral-border-weak">
        <div class="chapter">
            <div class="chapter-title">Data Collection</div>
            <div class="chapter-content">
                <p style="font-weight: bold;">Model training</p>
                <p> Use an existing dataset of Reddit comments for the initial training and testing of the model.</p>
                <ul>
                    <li><a href="https://www.kaggle.com/code/widhiwinata/twitter-and-reddit-sentiment-analysis">Twitter and Reddit Sentiment Analysis</a></li>
                </ul>
                <p style="font-weight: bold;">Actual analysis</p>
                <p>Use an API to collect the most recent 700 comments from specific subreddits.</p>
                <ul>
                    <li>Date of comment collection for this project: 2024/5/29</li>
                </ul>
            </div>
        </div>
        <hr class="w-100 my-sm border-neutral-border-weak">
        <div class="chapter">
            <div class="chapter-title">Data Processing</div>
            <div class="chapter-content">
                <p>This part is only used for the Bi-LSTM model. The BERT model use the tokenizer from BERT's pre-trained models.</p>
                <p style="font-weight: bold;">Text Cleaning and Tokenization</p>
                <ul>
                    <li>Remove all mentions containing '@' and links.</li>
                    <li>Use NLTK’s <code>word_tokenize</code> for tokenization.</li>
                    <li>Filter out all non-English characters from words.</li>
                </ul>
                <p style="font-weight: bold;">Lemmatization</p>
                <ul>
                    <li>Use NLTK’s <code>WordNetLemmatizer</code> and part-of-speech tagging to lemmatize each word.</li>
                </ul>
                <p style="font-weight: bold;">Dataset Splitting</p>
                <ul>
                    <li>80% training set</li>
                    <li>20% testing set.</li>
                </ul>
                <p style="font-weight: bold;">Vocabulary Building</p>
                <ul>
                    <li>Build a vocabulary from the words in the training set, assigning each unique word an integer index.</li>
                </ul>
                <p style="font-weight: bold;">Padding and Truncation</p>
                <ul>
                    <li>Use the number of words in the longest sentence from the training set as the standard.</li>
                    <li>Standardize the length of all sentences:</li>
                    <ul>
                        <li>Pad sentences that are too short with <code>'PAD'</code>.</li>
                        <li>Truncate sentences that are too long.</li>
                    </ul>
                </ul>
                <p style="font-weight: bold;">Encoding</p>
                <ul>
                    <li>Encode all data using the vocabulary.</li>
                    <li>Represent words not in the vocabulary as <code>'UNK'</code> for unknown.</li>
                </ul>
            </div>
        </div>
        <hr class="w-100 my-sm border-neutral-border-weak">
        <div class="chapter">
            <div class="chapter-title">Experimental Models</div>
            <div class="chapter-content">
                <p style="font-weight: bold;">Bi-LSTM</p>
                <ul>
                    <li>Use Bidirectional Long Short-Term Memory (Bi-LSTM) networks for text sentiment analysis.</li>
                    <li>Use <code>nn.Embedding</code> for word vectorization.</li>
                    <li>Capture textual dependencies using bidirectional LSTM to analyze context from both directions.</li>
                    <li>Process inputs through two fully connected layers with Dropout to reduce overfitting.</li>
                    <li>The output layer uses a Softmax function to determine the final sentiment category.</li>
                </ul>
                <p style="font-weight: bold;">BERT</p>
                <ul>
                    <li>Use the pre-trained <code>bert-base-uncased</code> tokenizer for text processing.</li>
                    <li>Extract features using the pre-trained BERT model.</li>
                    <li>Process inputs through a fully connected layers with Dropout to reduce overfitting.</li>
                    <li>The output layer uses a Softmax function to determine the final sentiment category.</li>
                </ul>
                <p>Both models are optimized using cross-entropy loss and the Adam optimizer, with performance evaluated based on accuracy, precision, recall, and F1-score.</p>
                <p>Both models are also managed and monitored on the Weights & Biases platform, enabling the tracking of various metrics throughout the training process.</p>
            </div>
        </div>
        <hr class="w-100 my-sm border-neutral-border-weak">
        <div class="chapter">
            <div class="chapter-title">Model training results</div>
            <div class="chapter-content">
                <p style="font-weight: bold;">Bi-LSTM</p>
                <br>
                <table>
                    <tr>
                        <th>Epochs</th>
                        <th>Learning rate</th>
                        <th>Batch size</th>
                        <th>Accuracy</th>
                        <th>Precision</th>
                        <th>Recall</th>
                        <th>F1-score</th>
                    </tr>
                    <tr>
                        <td>100</td>
                        <td>0.001</td>
                        <td>256</td>
                        <td>0.7454</td>
                        <td>0.7425</td>
                        <td>0.7454</td>
                        <td>0.7425</td>
                    </tr>
                    <tr>
                        <td>100</td>
                        <td>0.0001</td>
                        <td>256</td>
                        <td>0.6567</td>
                        <td>0.5985</td>
                        <td>0.6567</td>
                        <td>0.6065</td>
                    </tr>
                    <tr>
                        <td>150</td>
                        <td>0.001</td>
                        <td>256</td>
                        <td>0.7771</td>
                        <td>0.7758</td>
                        <td>0.7771</td>
                        <td>0.7764</td>
                    </tr>
                    <tr>
                        <td>150</td>
                        <td>0.0001</td>
                        <td>256</td>
                        <td>0.6767</td>
                        <td>0.6509</td>
                        <td>0.6767</td>
                        <td>0.6579</td>
                    </tr>
                </table>
                <img src="./src/img/LSTM_acc.png">
                <img src="./src/img/LSTM_f1.png">              
                <p style="font-weight: bold;">BERT</p>
                <br>
                <table>
                    <tr>
                        <th>Epochs</th>
                        <th>Learning rate</th>
                        <th>Batch size</th>
                        <th>Accuracy</th>
                        <th>Precision</th>
                        <th>Recall</th>
                        <th>F1-score</th>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td>0.00002</td>
                        <td>16</td>
                        <td>0.9436</td>
                        <td>0.9452</td>
                        <td>0.9436</td>
                        <td>0.9432</td>
                    </tr>
                    <tr>
                        <td style="font-weight: bold;">5</td>
                        <td style="font-weight: bold;">0.00002</td>
                        <td style="font-weight: bold;">16</td>
                        <td style="font-weight: bold;">0.9526</td>
                        <td style="font-weight: bold;">0.9536</td>
                        <td style="font-weight: bold;">0.9526</td>
                        <td style="font-weight: bold;">0.9529</td>
                    </tr>
                    <tr>
                        <td>5</td>
                        <td>0.00003</td>
                        <td>16</td>
                        <td>0.9524</td>
                        <td>0.9528</td>
                        <td>0.9524</td>
                        <td>0.9521</td>
                    </tr>
                    <tr>
                        <td>5</td>
                        <td>0.00001</td>
                        <td>16</td>
                        <td>0.9506</td>
                        <td>0.9513</td>
                        <td>0.9506</td>
                        <td>0.9508</td>
                    </tr>
                </table>
                <img src="./src/img/BERT_acc.png">
                <img src="./src/img/BERT_f1.png">
                <p>Our project finally chose to use the BERT model with the following settings: 5 epochs, a learning rate of 0.00002, and a batch size of 16, because it has the best performance across all metrics.</p>
            </div>
        </div>
        <hr class="w-100 my-sm border-neutral-border-weak">
        <div class="chapter">
            <div class="chapter-title">Data Visualization</div>
            <div class="chapter-content">
                
            </div>
        </div>
        <hr class="w-100 my-sm border-neutral-border-weak">
        <div class="chapter">
            <div class="chapter-title">Result Analysis</div>
            <div class="chapter-content">
                
            </div>
        </div>
        <hr class="w-100 my-sm border-neutral-border-weak">
        <div class="chapter">
            <div class="chapter-title">Future Works</div>
            <div class="chapter-content">
                <p style="font-weight: bold;">Time Trend Analysis</p>
                <p>Analyze how user sentiments evolve over time and in response to specific events, exploring the interrelationships between emotional shifts and significant occurrences.</p>
                <p style="font-weight: bold;">Real-Time Analysis</p>
                <p>Develop a feature that enables the system to automatically update daily, providing real-time tracking and analysis of sentiment among users of various subreddits.</p>
            </div>
        </div>
    </div>
    <div class="right-sidebar">
        <p class="right-sidebar-title">Team members</p>
        <div class="member">
            <img src="./src/img/Kiri.jpg">
            <div class="member-info">
                <div class="name">Kiri</div>
                <div class="info">110 NTUT EECS</div>
            </div>
        </div>
        <div class="member">
            <img src="./src/img/Shuan.jpg">
            <div class="member-info">
                <div class="name">Shuan</div>
                <div class="info">110 NTUT EECS</div>
            </div>
        </div>
    </div>
</div>